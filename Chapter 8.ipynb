{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Chapter-8:-MCMC\" data-toc-modified-id=\"Chapter-8:-MCMC-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Chapter 8: MCMC</a></div><div class=\"lev2 toc-item\"><a href=\"#Easy\" data-toc-modified-id=\"Easy-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Easy</a></div><div class=\"lev3 toc-item\"><a href=\"#8E1\" data-toc-modified-id=\"8E1-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>8E1</a></div><div class=\"lev3 toc-item\"><a href=\"#8E2\" data-toc-modified-id=\"8E2-112\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>8E2</a></div><div class=\"lev3 toc-item\"><a href=\"#8E3\" data-toc-modified-id=\"8E3-113\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>8E3</a></div><div class=\"lev3 toc-item\"><a href=\"#8E4\" data-toc-modified-id=\"8E4-114\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>8E4</a></div><div class=\"lev3 toc-item\"><a href=\"#8E5\" data-toc-modified-id=\"8E5-115\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>8E5</a></div><div class=\"lev3 toc-item\"><a href=\"#8E6\" data-toc-modified-id=\"8E6-116\"><span class=\"toc-item-num\">1.1.6&nbsp;&nbsp;</span>8E6</a></div><div class=\"lev2 toc-item\"><a href=\"#Medium\" data-toc-modified-id=\"Medium-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Medium</a></div><div class=\"lev3 toc-item\"><a href=\"#8M1\" data-toc-modified-id=\"8M1-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>8M1</a></div><div class=\"lev3 toc-item\"><a href=\"#8M2\" data-toc-modified-id=\"8M2-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>8M2</a></div><div class=\"lev3 toc-item\"><a href=\"#8M3\" data-toc-modified-id=\"8M3-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>8M3</a></div><div class=\"lev2 toc-item\"><a href=\"#Hard\" data-toc-modified-id=\"Hard-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Hard</a></div><div class=\"lev3 toc-item\"><a href=\"#8H1\" data-toc-modified-id=\"8H1-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>8H1</a></div><div class=\"lev3 toc-item\"><a href=\"#8H2\" data-toc-modified-id=\"8H2-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>8H2</a></div><div class=\"lev3 toc-item\"><a href=\"#8H3\" data-toc-modified-id=\"8H3-133\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>8H3</a></div><div class=\"lev2 toc-item\"><a href=\"#8H4\" data-toc-modified-id=\"8H4-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>8H4</a></div><div class=\"lev3 toc-item\"><a href=\"#8H5\" data-toc-modified-id=\"8H5-141\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>8H5</a></div><div class=\"lev3 toc-item\"><a href=\"#8H6\" data-toc-modified-id=\"8H6-142\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>8H6</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8E1\n",
    "\n",
    "Which of the following is a requirement of the simple Metropolis algorithm?\n",
    "\n",
    "(a) The parameters must be discrete.\n",
    "\n",
    "(b) The likelihood function must be Gaussian.\n",
    "\n",
    "(3) The proposal distribution must be symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8E2\n",
    "\n",
    "Gibbs sampling is more efficient than the Metropolis algorithm. How does it achieve this extra efficiency? Are there any limitations to the Gibbs sampling strategy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8E3\n",
    "\n",
    "Which sort of parameters can Hamiltonian Monte Carlo not handle? Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8E4\n",
    "\n",
    "Explain the difference between the effective number of  samples, `n_eff` as calculated by Stan, and the actual number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8E5\n",
    "\n",
    "Which value should `Rhat` approach, when a chain is sampling the posterior distribution correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8E6\n",
    "\n",
    "Sketch a good trace plot for a Markov chain, one that is effectively sampling from the posterior distribution. What is good about its shape? Then sketch a trace plot for a malfunctioning Markov chain. What about its shape indicates malfunction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8M1\n",
    "\n",
    "Re-estimate the terrain ruggedness model from the chapter, but now using a uniform prior and an exponential prior for the standard deviation, `sigma`. The uniform prior should be `dunif(0,10)` and the exponential should be `dexp(1)`. Do the different priors have any detectible influence on the posterior distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8M2\n",
    "\n",
    "The Cauchy and exponenential priors from the terrain ruggedness model are very weak. They can be made more informative by reducing their scale. Compare the `dcauchy` and `dexp` priors for progressively smaller values of the scaling parameter. As these priors become stronger, how does each influence the posterior distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8M3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-estimate one of the Stan models from the chapter, but at different numbers of `warmup` iterations. Be sure to use the same number of sampling iterations in each case. Compare the `n_eff` values. How much warmup is enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8H1\n",
    "\n",
    "Run the model below and then inspect the posterior distribution and explain what it is accomplishing.\n",
    "\n",
    "    mp <- map2stan(\n",
    "        alist(\n",
    "            a ~ dnorm(0,1),\n",
    "            b ~ dcauchy(0,1)\n",
    "        ),\n",
    "        data=list(y=1),\n",
    "        start=list(a=0, b=0),\n",
    "        iter=1e4,\n",
    "        warmup=100,\n",
    "        WAIC=false\n",
    "    )\n",
    "    \n",
    "Compare the samples for the parameters `a` and `b`. Can you explain the different trace plots, using what you know about the Cauchy distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8H2\n",
    "\n",
    "Recall the divorce rate example from Chapter 5. Repeat that analysis, using `map2stan` this time, fitting models `m5.1`, `m5.2`, and `m5.3`. Use `compare` to compare the models on the basis of WAIC. Explain the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8H3\n",
    "\n",
    "Sometimes changing a prior for one parameter has unanticipated effects on other parameters. This is because when a parameter is highly correlated with another parameter in the posterior, the prior influences both parameters. Here's an example to work and think through.\n",
    "\n",
    "Go back to the leg length example in Chapter 5. Here is the code again, which simulates height and leg lengths for 100 imagined individuals:\n",
    "\n",
    "    N <- 100                                 # number of individuals\n",
    "    height <- rnorm(N,10,2)                  # sim total height of each\n",
    "    leg_prop <- runif(N,0.4,0.5)             # leg as proportion of height\n",
    "    leg_left <- leg_prop*height +            # sim left leg as proportion + error\n",
    "        rnorm(N, 0, 0.2)\n",
    "    leg_right <- leg_prop*height +            # sim right leg as proportion + error\n",
    "        rnorm(N, 0, 0.2) \n",
    "                                             # combine into dataframe\n",
    "    d <- data.frame(height, leg_left, leg_right)    \n",
    "   \n",
    "And below is the model you fit before, resulting in a highly correlated posterior for the two beta parameters. This time, fit the model using `map2stan`:\n",
    "\n",
    "    m5.8 <- map2stan(\n",
    "        alist(\n",
    "            height ~ dnorm(mu, sigma),\n",
    "            mu <- a + bl*leg_left + br*leg_right,\n",
    "            a ~ dnorm(10,100),\n",
    "            bl ~ dnorm(2, 10),\n",
    "            br ~ dnorm(2, 10),\n",
    "            sigma ~ dcauchy(0, 1),\n",
    "        ),\n",
    "        data=d, chains=4,\n",
    "        start=list(a=10, bl=0, br=0, sigma=1)\n",
    "    )\n",
    "\n",
    "Compare the posterior distribution produced by the code above to the posterior distribution produced wehn you chang ethe prior for `br` so that it is strictly positive.\n",
    "\n",
    "    m5.8 <- map2stan(\n",
    "        alist(\n",
    "            height ~ dnorm(mu, sigma),\n",
    "            mu <- a + bl*leg_left + br*leg_right,\n",
    "            a ~ dnorm(10,100),\n",
    "            bl ~ dnorm(2, 10),\n",
    "            br ~ dnorm(2, 10) & T[0,],\n",
    "            sigma ~ dcauchy(0, 1),\n",
    "        ),\n",
    "        data=d, chains=4,\n",
    "        start=list(a=10, bl=0, br=0, sigma=1)\n",
    "    )\n",
    "    \n",
    "Note that `T[0,]` on the right-hand side of the prior for `br`. What the `T[0,]` does is _truncate_ the normal distribution so that it has positive probability only above zero. In other words, that prior ensures that the posterior distribution for `br` will have no probability mass below zero.\n",
    "\n",
    "Compare the two posterior distributions for `m5.8s` and `m5.8s2`. What has changed in the posterior distribution of both beta parameters? Can you explain the change induced by the change in prior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8H4\n",
    "\n",
    "For the two models fit in the previous problem, use DIC or WAIC to compare the effective numbers of parameters for each model. Which model has more effective parameters? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8H5\n",
    "\n",
    "Modify the Metropolis algorithm code from the chapter to handle the case that the island populations have a different distribution than the island labels. This means the island's number will not be the same as its population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8H6\n",
    "\n",
    "Modify the Metropolis algorithm code from the chapter to write your own simple MCMC estimator for globe tossing dat aand model from Chapter 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "422px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
